- make more saving standards (site-id-name-ext)
	This will enable people to handle files easily.
	Add caching so that if I run over someone I already downloaded I will get a quick with
		no downloading.
	Add the ability to run the tool over many people on many sites.
- show progress clearly so I will know how many urls there are to download.
	Shut the rest of the loggers off.
- getpocket work
	finish the scraper version of getpocket
	do a version of getpocket which is built on the official getpocket API.
		https://getpocket.com/developer/apps/new
		https://getpocket.com/developer/docs/authentication
- profiling work
	The result so far is that some modules take long to process
	examples are youtube_dl
	solution:
	Move this whole project to a plugin based system.
	Only load a plugin if you need it.
- don't download the same content twice in terms of signature.
- do my own db for downloaded stuff.
- add a more flexible file save mechanism that will not fail
	if the file names already exist.
- add ability to do several downloads in parallel.
	either with multi threading or multiprocessing.
- add scraper for pinterest.
- the current instagram downloader does not download videos
	It does download images for the videos.
	It currently download number of images = number of user
	posts + 1 (the main image of the user).
	So it downloads the images for the videos just not the
	videos themselves.
	fix this.
- add flag to control whether or not we add cookies from firefox
	or google or not at all.
	(default should be firefox).
- do website for this project and publish to github.
	use sphinx
- take some ideas from the google 'photograbber' project here:
	https://code.google.com/archive/p/photograbber/downloads
- use the facebook graph API to download from facebook:
	https://developers.facebook.com/docs/graph-api/reference/photo
- use the instagram API to create another crawler based on their API.
